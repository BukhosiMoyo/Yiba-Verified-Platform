# PROMPT 0 ‚Äî SYSTEM CONTEXT & SCOPE DEFINITION
## Intelligent Institution Outreach Engine (YibaWise / YibaVerified)

## READ THIS CAREFULLY BEFORE DOING ANY WORK

You are NOT building a traditional email marketing system.

You are enhancing an existing email feature into a **relationship-driven, identity-aware, AI-assisted outreach engine** designed specifically for **South African accredited institutions**.

This system must feel:
- Human
- Slow
- Intentional
- Trust-first
- Non-salesy

If your assumptions lean toward:
- Bulk campaigns
- Funnels
- Aggressive automation
- ‚ÄúMarketing software‚Äù behaviour

‚ùå STOP and reset.

---

## SYSTEM CONTEXT

### What exists today
- Admin uploads a list of institution emails
- System sends emails
- Tracks clicks and acceptance
- Very limited logic
- No awareness stages
- No personalisation
- No journey visibility

This is NOT enough.

---

## WHAT WE ARE BUILDING INSTEAD

We are building an **Institution Relationship Engine**.

This engine:
- Treats each institution as a long-term relationship
- Tracks a full journey over time
- Responds based on behaviour and intent
- Uses AI ONLY after the institution engages
- Never pressures, never sells upfront

---

## TARGET USER (CRITICAL)

Primary target:
- **Institution Admins (SDPs / Colleges / Providers)**

Secondary (beneficiaries, not targets):
- QCTO
- CETAs
- Regulators

Important:
- Government bodies are NOT marketed to via this system
- QCTO engagement is handled manually and strategically
- This engine is for institutions only

---

## CORE PHILOSOPHY

We are NOT trying to ‚Äúconvert‚Äù.

We are trying to:
- Educate
- Build trust
- Reduce fear
- Increase clarity
- Create voluntary adoption

If institutions WANT to use the system,
compliance becomes automatic.

---

## NON-NEGOTIABLE RULES

1. No bulk-thinking  
   Every institution has its own journey.

2. No aggressive selling  
   Monetisation happens later, psychologically and ethically.

3. AI does NOT initiate conversations  
   AI only responds after a human action.

4. Identity is mandatory  
   Every click, page view, answer, and email must be tied to a unique institution identity.

5. Build incrementally  
   - Plan first  
   - Design second  
   - Implement third  
   - Test before moving on  

Do NOT build everything at once.

---

## WHAT YOU MUST DO NOW

Your task in THIS prompt is ONLY to:

1. Acknowledge understanding of the system goals
2. Restate the system in your own words (briefly)
3. Confirm that this is NOT an email marketing tool
4. Confirm that work will proceed **one stage at a time**
5. Wait for the next prompt

DO NOT:
- Design UI
- Create schemas
- Write copy
- Suggest tools
- Jump ahead

---

## EXPECTED OUTPUT FORMAT

Respond with:

- A short confirmation section
- A clear restatement of the system purpose
- Explicit confirmation that you will proceed step-by-step

Nothing else.

---

## WAIT FOR THE NEXT PROMPT

---

# PROMPT 1 ‚Äî ENGAGEMENT STATES & RESPONSE CLASSIFICATION
## Intelligent Institution Outreach Engine (YibaWise / YibaVerified)

## PURPOSE OF THIS PROMPT

We are defining the **foundation logic** for how institutions are classified **after the first email is sent**.

This is NOT implementation yet.
This is **behaviour modelling**.

If this layer is wrong, everything breaks later.

---

## CORE CONCEPT

Each institution exists in **exactly one engagement state at a time**.

States change only through **explicit actions**, never assumptions.

Silence is a state.
Clicks are a state.
Declines are a state.
Replies are a state.

---

## BASE ENGAGEMENT STATES (V1 ‚Äî DO NOT EXPAND YET)

You must define the following canonical states:

### STATE 0 ‚Äî SEEDED
- Institution email exists in the system
- No email sent yet

---

### STATE 1 ‚Äî CONTACTED
- First email sent
- No interaction yet
- Timer starts (used later for pacing)

---

### STATE 2 ‚Äî OPENED
- Email opened
- No link clicked
- Indicates light curiosity, not intent

---

### STATE 3 ‚Äî CLICKED
- Link clicked from email
- Identity confirmed via unique token
- This is the **first trust signal**

---

### STATE 4 ‚Äî ENGAGED
- Institution interacts with a page
- Examples:
  - Answers at least one question
  - Proceeds past intro screen
- This is where AI MAY become active later

---

### STATE 5 ‚Äî REVIEWING
- Institution is actively reading / stepping through value explanation
- No commitment yet
- This is an education phase, not onboarding

---

### STATE 6 ‚Äî ACCEPTED
- Institution explicitly chooses to proceed
- This leads into onboarding flows (handled later)

---

### STATE 7 ‚Äî DECLINED
- Institution explicitly declines
- Decline reason must be captured (structured)
- Optional free-text message allowed

---

### STATE 8 ‚Äî INACTIVE
- No interaction after a defined cooling-off period
- NOT a rejection
- Eligible for future re-engagement

---

## RESPONSE CLASSIFICATION RULES

You must enforce the following:

1. **No implicit transitions**
   - Opens ‚â† interest
   - Clicks ‚â† acceptance

2. **Decline is explicit**
   - Decline must be a deliberate action
   - One reason only (radio select)
   - ‚ÄúOther‚Äù reveals a text field

3. **AI is locked until STATE 4**
   - Before that: static copy only
   - After that: AI may respond contextually

4. **Institutions can move backwards**
   - From REVIEWING ‚Üí INACTIVE
   - From ENGAGED ‚Üí REVIEWING
   - But never from DECLINED ‚Üí ACTIVE automatically

---

## DATA THAT MUST BE RECORDED PER TRANSITION

For every state change, log:
- Institution ID
- Previous state
- New state
- Trigger action
- Timestamp
- Source (email, page, manual)

This is non-negotiable.

---

## WHAT YOU MUST DO NOW

Your task in THIS prompt is ONLY to:

1. Confirm these engagement states
2. Validate transitions between them
3. Flag edge cases or conflicts
4. Propose a clean internal naming convention (constants / enums)

DO NOT:
- Design UI
- Write copy
- Implement AI
- Suggest email content
- Jump to onboarding

---

## OUTPUT FORMAT REQUIRED

Respond with:
- Confirmation of state list
- Transition table (simple)
- Any risks you see
- A short ‚Äúready to proceed‚Äù note

---

## WAIT FOR THE NEXT PROMPT

---

# PROMPT 2 ‚Äî REVIEW INVITATION WALKTHROUGH LOGIC
## Institution Education Layer (Pre-Onboarding)

## PURPOSE OF THIS PROMPT

We are defining the **Review Invitation experience**.

This is **NOT onboarding**.
This is **NOT account setup**.

This layer exists to:
- Build trust
- Educate
- Let institutions self-qualify
- Reduce fear before commitment

Institutions must feel informed, not sold.

---

## CORE PRINCIPLE

**Review ‚â† Accept**

The review flow says:
‚ÄúUnderstand what this system is, before you decide.‚Äù

---

## WHEN THIS FLOW IS TRIGGERED

This walkthrough is shown ONLY when:
- Institution is in STATE 3 (CLICKED)
- OR STATE 4 (ENGAGED)
- AND they choose **‚ÄúReview Invitation‚Äù**

It must NEVER appear for:
- Platform admins
- Staff
- Students

---

## STRUCTURE OF THE REVIEW WALKTHROUGH

The review experience is:

- A **dedicated page**
- With a **centered modal / card**
- Surrounded by a neutral, branded background
- No dashboard visible
- No login UI reused

---

## WALKTHROUGH FORMAT

### CARD-BASED SEQUENCE

- Fixed-size cards
- One card in focus at a time
- Horizontal movement:
  - Next ‚Üí slide left
  - Back ‚Üí slide right
- Adjacent cards visible but blurred
- Progress indicator at top (pill-style, not dots)

NO auto-play  
NO timers  
User controls progression

---

## REQUIRED WALKTHROUGH STEPS (V1)

You must implement **exactly these steps** in this order:

### STEP 1 ‚Äî Welcome & Context
- What YibaWise / YibaVerified is
- Who it is for
- Why it exists

Goal: Orientation, not persuasion

---

### STEP 2 ‚Äî The Problem Being Solved
- Manual compliance pain
- Fragmentation
- Risk to institutions & students

Goal: ‚ÄúThis feels familiar‚Äù

---

### STEP 3 ‚Äî How the System Helps
- Live visibility
- Structured submissions
- Less admin burden

Goal: Reduce perceived workload

---

### STEP 4 ‚Äî What Is Expected From the Institution
- Data that will be required
- Ongoing responsibilities
- Transparency expectations

Goal: No surprises later

---

### STEP 5 ‚Äî Trust & Alignment
- QCTO alignment
- Auditability
- Neutral infrastructure stance

Goal: Credibility

---

### STEP 6 ‚Äî Decision Point
Two primary actions:
- **Accept Invitation**
- **Decline Invitation**

Secondary:
- Back to previous step

---

## ACCEPT LOGIC

If user clicks **Accept Invitation**:
- Transition state ‚Üí ACCEPTED
- Proceed to onboarding (handled later)
- No further review steps shown

---

## DECLINE LOGIC (MANDATORY)

If user clicks **Decline Invitation**:
- Show a secondary modal
- Emotional but respectful tone

### Decline modal must include:
- One selectable reason (radio):
  - Using another platform
  - Manual process works for us
  - Not ready right now
  - Not accredited
  - Other
- ‚ÄúOther‚Äù reveals a text field
- One reason only allowed
- Optional message

After submission:
- State ‚Üí DECLINED
- Data stored for analytics & future re-engagement
- User exits flow gracefully

---

## DATA TO RECORD

For the review walkthrough, record:
- Step completion
- Time spent per step
- Final action (accept / decline)
- Decline reason (if applicable)

---

## WHAT YOU MUST DO NOW

In this prompt, you must:

1. Validate the step order
2. Confirm accept vs review separation
3. Identify UX or logic risks
4. Suggest internal structure for storing walkthrough progress

DO NOT:
- Write final copy
- Design animations
- Implement onboarding
- Merge this with login flows

---

## WAIT FOR THE NEXT PROMPT

---

# PROMPT 3 ‚Äî AI Objection Handling Rules (Gold Standard)

## Objective
Design and implement **AI-assisted objection handling** for Institution Admin outreach in a way that feels:
- Human
- Respectful
- Non-salesy
- Trust-building
- Safe for government-adjacent communication

This AI is **not a salesperson**.
It is a **patient guide and listener**.

---

## 1Ô∏è‚É£ When AI Is Allowed to Respond

AI responses are ONLY triggered when:
- An institution **actively responds** (via email reply or in-platform message)
- An institution selects **‚ÄúOther‚Äù** and types a message
- An institution explicitly raises a concern or objection

AI must NEVER:
- Chase ignored users aggressively
- Invent urgency
- Apply pressure
- Pretend to be a human individual

---

## 2Ô∏è‚É£ Objection Classification (Required)

Every inbound message MUST first be classified into **one and only one** category:

### Objection Types
1. **Using Another Platform**
2. **Manual Process Is Working**
3. **Too Busy / Not Now**
4. **Don‚Äôt Understand the System**
5. **Concern About Cost**
6. **Concern About Data / Trust**
7. **Already Working With QCTO**
8. **General Skepticism**
9. **Positive but Not Ready**
10. **Hard Rejection**
11. **Other (Free Text)**

Classification must be stored in the database:
- objection_type
- original_message
- timestamp

---

## 3Ô∏è‚É£ AI Response Rules (Hard Constraints)

AI responses MUST:

‚úÖ Acknowledge the concern  
‚úÖ Reflect the user‚Äôs words back  
‚úÖ Provide clarity, not persuasion  
‚úÖ Offer ONE optional next step  
‚úÖ Allow exit at any time  

AI responses MUST NOT:

‚ùå Sell  
‚ùå Promise outcomes  
‚ùå Mention pricing  
‚ùå Mention competitors negatively  
‚ùå Argue  
‚ùå Over-explain  
‚ùå Sound scripted  

---

## 4Ô∏è‚É£ Tone & Voice Rules

The AI voice must feel like:
- A calm platform representative
- Neutral, professional, warm
- Respectful of institutional autonomy

Tone characteristics:
- Plain language
- Short paragraphs
- No emojis
- No hype
- No buzzwords

Example tone reference:
> ‚ÄúThanks for sharing that ‚Äî it helps us understand where you‚Äôre coming from.‚Äù

---

## 5Ô∏è‚É£ Example Objection ‚Üí Response Patterns

### Objection: ‚ÄúWe already use another system‚Äù
AI Response Pattern:
- Acknowledge existing setup
- Clarify this platform does not replace immediately
- Offer optional comparison walkthrough
- Exit gracefully

### Objection: ‚ÄúManual works for us‚Äù
AI Response Pattern:
- Respect their process
- Highlight visibility, not replacement
- Offer review-only walkthrough
- No urgency

### Objection: ‚ÄúWe‚Äôre too busy‚Äù
AI Response Pattern:
- Validate time pressure
- Offer pause / reminder option
- Ask preferred timing
- Stop if no reply

---

## 6Ô∏è‚É£ Escalation Rules (Very Important)

AI must STOP responding when:
- User says ‚ÄúNot interested‚Äù
- User says ‚ÄúPlease stop‚Äù
- User does not respond after 2 AI replies

When escalation is required:
- Flag conversation for human review
- Do NOT continue automated messaging

---

## 7Ô∏è‚É£ Memory & Context Rules

AI is allowed to remember:
- Objection category
- Engagement stage
- Last interaction date

AI is NOT allowed to:
- Assume intent
- Change tone based on guesses
- Refer to internal scores or rankings

---

## 8Ô∏è‚É£ Success Criteria

This system is successful if:
- Institutions feel respected
- Responses feel tailored
- No complaints of spam or pressure
- Engagement continues voluntarily

---

## 9Ô∏è‚É£ Non-Goal (Explicit)

This AI is NOT designed to:
- Close deals
- Push sign-ups
- Replace human outreach
- ‚ÄúConvert‚Äù unwilling institutions

Its job is to:
> Reduce friction, increase clarity, and preserve trust.

---

## 10Ô∏è‚É£ Implementation Notes

- Implement classification BEFORE response generation
- Store all objection data for analytics
- Keep prompts versioned and auditable
- Allow manual override by Platform Admin

---

# PROMPT 4 ‚Äî Engagement State Machine (Technical)

## Objective
Design a **deterministic, auditable engagement state machine** that governs how institutions move through awareness, trust, onboarding, and activation ‚Äî without randomness, pressure, or spam behavior.

This state machine is the **single source of truth** for:
- What message is allowed
- When it is allowed
- Why it is allowed
- What happens next

---

## 1Ô∏è‚É£ Core Principle

Institutions never ‚Äúfall through cracks‚Äù  
and are never ‚Äúchased blindly‚Äù.

Every institution is always in **exactly one state**.

---

## 2Ô∏è‚É£ Primary Engagement States (Top Level)

Each institution must belong to ONE of the following:

1. `UNCONTACTED`
2. `CONTACTED_AWARENESS`
3. `ENGAGED_DISCOVERY`
4. `ENGAGED_REVIEW`
5. `ONBOARDING_STARTED`
6. `ONBOARDING_COMPLETED`
7. `ACTIVE_USER`
8. `PAUSED`
9. `DECLINED`
10. `DO_NOT_CONTACT`

---

## 3Ô∏è‚É£ State Definitions & Entry Conditions

### 1. UNCONTACTED
- Institution exists in database
- No emails sent

‚û° Entry: Seed list import  
‚û° Exit: First outreach email sent

---

### 2. CONTACTED_AWARENESS
- First email delivered
- No interaction yet

‚û° Entry: Email sent  
‚û° Exit:
- Link click
- Explicit reply
- Time-based progression (optional, slow)

---

### 3. ENGAGED_DISCOVERY
- Institution clicked link
- Viewed content
- Answered initial questions

‚û° Entry: Landing page interaction  
‚û° Exit:
- Review invitation clicked
- Objection submitted
- No response ‚Üí PAUSED

---

### 4. ENGAGED_REVIEW
- Institution chose ‚ÄúReview Invitation‚Äù
- Walkthrough viewed

‚û° Entry: Review flow started  
‚û° Exit:
- Accept invitation
- Decline invitation

---

### 5. ONBOARDING_STARTED
- Invitation accepted
- Account created
- Setup not completed

‚û° Entry: Account creation  
‚û° Exit:
- Setup completed
- Abandoned ‚Üí PAUSED

---

### 6. ONBOARDING_COMPLETED
- Institution profile completed
- Ready for system usage

‚û° Entry: Final onboarding step  
‚û° Exit: First operational action

---

### 7. ACTIVE_USER
- Using LMIS / submissions / attendance

‚û° Entry: First real action  
‚û° Exit:
- Long inactivity ‚Üí PAUSED
- Explicit exit ‚Üí DECLINED

---

### 8. PAUSED
- Temporarily inactive
- No pressure allowed

‚û° Entry:
- ‚ÄúNot now‚Äù
- No response
- Time-based cooldown

‚û° Exit:
- Manual re-engagement
- User-initiated action

---

### 9. DECLINED
- Explicit rejection
- Reason recorded

‚û° Entry: Decline action  
‚û° Exit: Human-approved re-engagement only

---

### 10. DO_NOT_CONTACT
- Legal or explicit opt-out

‚û° Entry: Opt-out  
‚û° Exit: NEVER (hard stop)

---

## 4Ô∏è‚É£ Allowed Transitions (Hard Rules)

- States may only change via:
  - User action
  - Explicit system event
  - Manual admin override

‚ùå No automatic skipping  
‚ùå No looping without consent  
‚ùå No silent reactivation  

---

## 5Ô∏è‚É£ Event ‚Üí State Mapping

| Event | State Change |
|-----|-------------|
Email Sent | UNCONTACTED ‚Üí CONTACTED_AWARENESS |
Link Click | CONTACTED ‚Üí ENGAGED_DISCOVERY |
Review Click | ENGAGED_DISCOVERY ‚Üí ENGAGED_REVIEW |
Accept Invite | ENGAGED_REVIEW ‚Üí ONBOARDING_STARTED |
Complete Setup | ONBOARDING_STARTED ‚Üí ONBOARDING_COMPLETED |
First Use | ONBOARDING_COMPLETED ‚Üí ACTIVE_USER |
No Response | Any ‚Üí PAUSED |
Explicit Decline | Any ‚Üí DECLINED |
Opt-Out | Any ‚Üí DO_NOT_CONTACT |

---

## 6Ô∏è‚É£ Technical Requirements

- Store state in DB (single column)
- Store transition history (audit table)
- Enforce transitions in backend (not UI)
- Block invalid transitions
- Log every state change with:
  - from_state
  - to_state
  - reason
  - timestamp
  - actor (system / user / admin)

---

## 7Ô∏è‚É£ Why This Matters

This prevents:
- Spam
- Confusion
- Trust erosion
- ‚ÄúWhy am I getting this email?‚Äù moments

This enables:
- Clear analytics
- Predictable behavior
- Ethical growth
- Government-grade accountability

---

## 8Ô∏è‚É£ Non-Goals

This is NOT:
- A marketing automation engine
- A funnel spam system
- A sales CRM clone

It is a **trust-based engagement controller**.

---

## 9Ô∏è‚É£ Success Criteria

- Every institution‚Äôs journey is explainable
- No message is sent ‚Äúby accident‚Äù
- Platform admins can answer:
  ‚ÄúWhy did this institution receive this message?‚Äù

---

## 10Ô∏è‚É£ Next Prompt Dependency

This state machine is REQUIRED before:
- AI email generation
- Scoring systems
- Automation rules
- Dashboard analytics

---

# PROMPT 5 ‚Äî Review Invitation Walkthrough (UX + Logic)

## Objective
Design a **non-salesy, trust-first Review Invitation experience** for **Institution Admins only**, allowing them to *understand value before committing*, without forcing account creation.

This is NOT onboarding.
This is NOT registration.
This is a **guided understanding layer**.

---

## 1Ô∏è‚É£ Who This Is For (Hard Rule)

‚úÖ Institution Admins  
‚ùå Platform Admins  
‚ùå QCTO Users  
‚ùå Staff / Students  

Only Institution Admins may see the **Review Invitation** option.

---

## 2Ô∏è‚É£ Entry Conditions

The Review Invitation walkthrough is accessible ONLY when:

- Institution is in `ENGAGED_DISCOVERY`
- User clicks **‚ÄúReview Invitation‚Äù** from email or landing page
- A valid invite token exists

‚ùå Direct URL access without token is blocked  
‚ùå Logged-in users do NOT see this flow again  

---

## 3Ô∏è‚É£ UX Structure (High Level)

This is a **standalone full-page experience**, NOT reused login UI.

### Visual Structure
- Blurred, animated background (subtle motion)
- Centered floating card
- Fixed-width card (desktop & mobile safe)
- Step-based progression
- No auto-advance
- Explicit user control

---

## 4Ô∏è‚É£ Walkthrough Steps (Content Logic)

### STEP 1 ‚Äî Welcome & Context
**Purpose:** Reduce anxiety, set tone

Content:
- Welcome to YibaWise / YibaVerified
- Why institutions are being invited
- Alignment with QCTO (non-commercial tone)

CTA:
- `Next`
- `Decline Invitation`

---

### STEP 2 ‚Äî The Problem We Solve
**Purpose:** Problem-aware positioning

Content:
- Manual compliance is risky
- CSVs, emails, site visits
- No live visibility
- High admin burden

CTA:
- `Next`
- `Back`

---

### STEP 3 ‚Äî What This Platform Changes
**Purpose:** Value clarity

Content:
- Live compliance visibility
- Attendance & submissions generated from system data
- Reduced audit stress
- One source of truth

CTA:
- `Next`
- `Back`

---

### STEP 4 ‚Äî What You Control
**Purpose:** Remove fear of loss of control

Content:
- You own your data
- You decide what is submitted
- Nothing is auto-sent without approval
- QCTO visibility is transparent

CTA:
- `Next`
- `Back`

---

### STEP 5 ‚Äî What Happens If You Join
**Purpose:** Set expectations

Content:
- Short onboarding
- Profile setup
- Start using LMIS features
- No payment required

CTA:
- `Accept Invitation`
- `Back`

---

### STEP 6 ‚Äî Accept or Decline
**Purpose:** Explicit choice

Buttons:
- `Accept Invitation` (Primary)
- `Decline Invitation` (Secondary)

---

## 5Ô∏è‚É£ Decline Flow (Mandatory)

If **Decline Invitation** is clicked:

### Decline Modal
- Friendly tone
- Sad/empathetic animated emoji
- Single-select reason (required)

Reasons:
- Using another system
- Not ready right now
- Manual process preferred
- Not relevant
- Other (shows message input)

Rules:
- Only ONE reason selectable
- ‚ÄúOther‚Äù reveals text area
- Submission required to proceed

Data Stored:
- Decline reason
- Optional message
- Timestamp
- Invite token reference

---

## 6Ô∏è‚É£ Outcomes & State Transitions

| Action | State Change |
|-----|-------------|
Accept Invitation | ‚Üí ONBOARDING_STARTED |
Decline Invitation | ‚Üí DECLINED |
Exit / Close | ‚Üí PAUSED |

---

## 7Ô∏è‚É£ Technical Requirements

- Step index stored client-side
- Final action stored server-side
- Progress indicators (pill-style)
- Back button always available (except step 1)
- Fully responsive
- Light & dark mode supported

---

## 8Ô∏è‚É£ Non-Goals

This walkthrough must NOT:
- Ask for credentials
- Ask for documents
- Ask for compliance data
- Contain pricing
- Feel like marketing

---

## 9Ô∏è‚É£ Success Criteria

- Institutions feel informed, not pressured
- Declines provide insight (not silence)
- Acceptances are intentional
- Trust is built before commitment

---

## 10Ô∏è‚É£ Dependency

This flow depends on:
- Engagement State Machine (PROMPT 4)

Next steps after this:
- AI objection handling
- Email reply behavior
- Scoring logic

---

# PROMPT 6 ‚Äî AI Reply Behavior & Objection Handling (Institution Admins)

## Objective
Define **strict AI behavior rules** for responding to Institution Admins **after engagement**, ensuring replies feel human, contextual, respectful, and never salesy.

This AI does NOT sell.
This AI guides, clarifies, reassures, and listens.

---

## 1Ô∏è‚É£ When AI Is Allowed to Respond

AI-generated replies are allowed ONLY when:

- Institution has interacted (clicked / answered / declined / replied)
- Engagement state is NOT `UNCONTACTED`
- A human-style reply is appropriate

AI must NEVER initiate first contact.

---

## 2Ô∏è‚É£ AI Identity & Tone Rules

### Identity
- AI speaks **as the platform team**, not ‚Äúan AI‚Äù
- No technical jargon
- No marketing language
- Calm, respectful, professional

### Tone
- Conversational
- Empathetic
- Short, clear paragraphs
- No hype, no urgency pressure

‚ùå No ‚ÄúDon‚Äôt miss out‚Äù
‚ùå No ‚ÄúLimited time‚Äù
‚ùå No sales CTAs

---

## 3Ô∏è‚É£ Response Classification (Input Types)

AI must classify responses into ONE category before replying:

### A. Curious / Neutral
Examples:
- ‚ÄúThis looks interesting‚Äù
- ‚ÄúCan you explain more?‚Äù
- ‚ÄúHow does this work?‚Äù

### B. Objection-Based
Examples:
- ‚ÄúWe already use another system‚Äù
- ‚ÄúWe prefer manual processes‚Äù
- ‚ÄúThis looks complicated‚Äù

### C. Timing-Based
Examples:
- ‚ÄúNot now‚Äù
- ‚ÄúMaybe later this year‚Äù
- ‚ÄúWe‚Äôre busy at the moment‚Äù

### D. Trust-Based
Examples:
- ‚ÄúIs this endorsed by QCTO?‚Äù
- ‚ÄúIs our data safe?‚Äù
- ‚ÄúWho owns the data?‚Äù

### E. Decline / Closed
Examples:
- Explicit rejection
- Negative sentiment

---

## 4Ô∏è‚É£ Response Strategy Per Category

### A. Curious / Neutral
Goal: Educate gently

Response Rules:
- Answer only what was asked
- Invite review invitation if not completed
- No next-step pressure

---

### B. Objection-Based
Goal: Reframe without arguing

Rules:
- Acknowledge first
- Do NOT contradict
- Explain how system coexists, not replaces
- Offer comparison without attacking alternatives

---

### C. Timing-Based
Goal: Respect autonomy

Rules:
- Thank them
- Ask permission to follow up later
- No immediate CTA
- Move state to `PAUSED`

---

### D. Trust-Based
Goal: Build confidence

Rules:
- Reference transparency
- Mention alignment (not endorsement)
- Explain data ownership clearly
- Keep it factual

---

### E. Decline / Closed
Goal: Exit gracefully

Rules:
- Thank them
- Confirm no further emails
- Keep door open
- Move state to `DECLINED`

---

## 5Ô∏è‚É£ Hard Boundaries (Must Never Happen)

AI must NEVER:
- Mention pricing
- Mention competitors by name
- Argue with objections
- Push onboarding
- Ask for documents
- Ask for credentials

---

## 6Ô∏è‚É£ Personalisation Rules

AI may use:
- Institution name
- Previous answers
- Stated concerns

AI may NOT infer:
- Financial capacity
- Compliance risk
- Intent to join

---

## 7Ô∏è‚É£ Memory & Context Handling

For each institution, store:
- Last interaction
- Objection category
- Last response summary
- Engagement state

AI must reference ONLY stored facts.

---

## 8Ô∏è‚É£ Escalation Rules

If:
- Response is unclear
- Message is emotional
- Message is complex

Then:
- Flag for human review
- Do NOT auto-reply

---

## 9Ô∏è‚É£ Success Criteria

- Replies feel written by a thoughtful human
- Institutions feel heard
- No pressure is applied
- Trust increases over time

---

## 10Ô∏è‚É£ Dependency

Depends on:
- Engagement State Machine
- Review Invitation logic
- Email routing system

Next prompt will define:
- Engagement state transitions (technical)

---

# PROMPT 7 ‚Äî Engagement State Machine (Technical Source of Truth)

## Objective
Define a **deterministic engagement state machine** for Institution Admin outreach.
This state machine controls:
- Which emails can be sent
- When AI may respond
- Which UI flows are unlocked
- What follow-ups are allowed

This is the **single source of truth** for engagement logic.

---

## 1Ô∏è‚É£ Core Principle

An institution is ALWAYS in exactly **one state**.

State changes only occur via:
- Explicit user action
- Time-based rules
- Admin override

No state skipping.
No ambiguous states.

---

## 2Ô∏è‚É£ Engagement States (Canonical List)

### STATE 0 ‚Äî UNCONTACTED
- Institution exists in database
- No communication sent

Allowed Actions:
- Send first awareness email

Disallowed:
- AI replies
- Follow-ups
- Review invitation

---

### STATE 1 ‚Äî CONTACTED
- First email sent
- No interaction yet

Allowed:
- Track open / click
- Passive analytics only

Transitions:
- Click ‚Üí ENGAGED
- No action (X days) ‚Üí DORMANT

---

### STATE 2 ‚Äî ENGAGED
- Link clicked OR email replied
- No decision made yet

Allowed:
- Show landing page
- Ask lightweight questions
- AI reply allowed

Transitions:
- Answers submitted ‚Üí EVALUATING
- Explicit decline ‚Üí DECLINED
- No activity (X days) ‚Üí PAUSED

---

### STATE 3 ‚Äî EVALUATING
- Institution answering questions
- Reviewing content
- Reading walkthroughs

Allowed:
- Review Invitation walkthrough
- AI clarification replies
- Educational follow-ups

Transitions:
- Review completed ‚Üí READY
- Decline ‚Üí DECLINED
- Time delay ‚Üí PAUSED

---

### STATE 4 ‚Äî READY
- Institution shows intent
- Clicked ‚ÄúAccess Dashboard‚Äù OR completed review

Allowed:
- Account activation
- Password setup
- Onboarding start

Transitions:
- Onboarding completed ‚Üí ACTIVE
- Abandon ‚Üí PAUSED

---

### STATE 5 ‚Äî ACTIVE
- Institution admin account live
- Using platform

Allowed:
- Operational emails
- System notifications
- No marketing emails

---

### STATE 6 ‚Äî PAUSED
- Institution requested delay OR inactive

Allowed:
- Gentle check-in after cooldown
- No AI persuasion

Transitions:
- Re-engagement ‚Üí ENGAGED
- No response (long term) ‚Üí ARCHIVED

---

### STATE 7 ‚Äî DECLINED
- Institution explicitly declined

Allowed:
- Confirmation email
- No further outreach

Hard Stop:
- No follow-ups
- No AI replies
- No re-entry unless manually reset

---

### STATE 8 ‚Äî DORMANT
- Never engaged after contact
- Silent non-response

Allowed:
- One reactivation attempt after long delay

Transitions:
- Engagement ‚Üí ENGAGED
- No response ‚Üí ARCHIVED

---

### STATE 9 ‚Äî ARCHIVED
- End of lifecycle

Allowed:
- None (read-only)

---

## 3Ô∏è‚É£ Transition Rules (Strict)

- States can only move forward or sideways (never backward)
- DECLINED and ARCHIVED are terminal
- ACTIVE is stable (marketing disabled)

---

## 4Ô∏è‚É£ Technical Requirements

Each institution must store:
- current_state
- last_state_change_at
- last_interaction_at
- last_email_sent_at

State changes must be:
- Logged
- Auditable
- Timestamped

---

## 5Ô∏è‚É£ Enforcement Rules

Before any action:
- Validate current state
- Validate allowed actions for that state

If invalid:
- Block action
- Log violation

---

## 6Ô∏è‚É£ Why This Matters

This prevents:
- Spam
- Conflicting messages
- Over-automation
- Trust erosion

This enables:
- Predictable behavior
- Safe AI usage
- Clean analytics
- Long-term relationships

---

## 7Ô∏è‚É£ Dependency

Depends on:
- Response Classification
- AI Reply Rules
- Review Invitation Flow

Next prompt will define:
- Landing pages & question flow logic

---

# PROMPT 8 ‚Äî Landing Pages & Progressive Question Flow Logic

## Objective
Design a **progressive, state-aware landing page system** that:
- Collects information without friction
- Adapts questions based on prior responses
- Feels conversational, not form-heavy
- Feeds directly into the engagement state machine

This replaces static forms with **guided decision paths**.

---

## 1Ô∏è‚É£ Core Principle

No long forms.  
No overwhelming screens.  
No generic questionnaires.

Each interaction should feel like:
> ‚ÄúOne simple question at a time.‚Äù

---

## 2Ô∏è‚É£ Landing Page Architecture

### Single Dynamic Route
Use ONE canonical route: /engage/[token]

Where:
- `token` = unique per institution
- Token resolves:
  - Institution ID
  - Current engagement state
  - Prior answers (if any)

---

## 3Ô∏è‚É£ Page Structure (UI Rules)

Each step must contain:
- Clear headline (1 sentence)
- Short context (1‚Äì2 lines max)
- One question OR decision
- Primary action button
- Secondary option (if applicable)

No scrolling required per step.

---

## 4Ô∏è‚É£ Question Types (Allowed)

### A. Single-Select (Radio)
Used for:
- Current compliance method
- Platform usage
- Readiness level

Example:
> How do you currently submit data to QCTO?

- Manual (Email / Paper)
- CSV uploads
- Another platform
- Not submitting consistently

---

### B. Multi-Select (Checkbox)
Used sparingly for:
- Challenges
- Pain points

Example:
> What‚Äôs hardest about compliance right now?

- Keeping records up to date  
- Preparing for audits  
- Tracking attendance  
- Submitting evidence  

---

### C. Conditional Free Text
ONLY shown when:
- ‚ÄúOther‚Äù is selected
- Objection is expressed

Never show text boxes by default.

---

## 5Ô∏è‚É£ Progressive Logic Rules

Each answer determines:
- Next question
- Copy tone
- Engagement state transition

Example:
- Manual ‚Üí show visibility benefits
- CSV ‚Üí show automation benefits
- Another platform ‚Üí ask soft comparison question
- Not submitting ‚Üí show risk awareness content

---

## 6Ô∏è‚É£ State Transitions (Integration)

| Action | Resulting State |
|------|----------------|
Answer first question | ENGAGED |
Complete 2‚Äì3 steps | EVALUATING |
Click ‚ÄúReview Invitation‚Äù | EVALUATING |
Click ‚ÄúAccess Dashboard‚Äù | READY |
Explicit decline | DECLINED |

---

## 7Ô∏è‚É£ Data Storage Requirements

For each interaction store:
- Question ID
- Answer(s)
- Timestamp
- Engagement state at time of answer

Answers must be:
- Immutable (append-only)
- Auditable
- Replayable for analytics

---

## 8Ô∏è‚É£ UX Safeguards

- Progress indicator (pills, not percentages)
- Back button (previous step only)
- Exit option (does not equal decline)

If user exits:
- Save progress
- Move to PAUSED after inactivity

---

## 9Ô∏è‚É£ What This Enables

- AI-aware personalization
- Objection handling
- Intent scoring
- Clean segmentation
- Future re-engagement

---

## üîü Explicit Non-Goals

Do NOT:
- Collect sensitive data
- Ask for payment
- Ask for login
- Show dashboards

This is **trust-building only**.

---

## Dependency
Requires:
- Engagement State Machine (PROMPT 7)

Next prompt will define:
- AI response generation rules per state

---

# PROMPT 9 ‚Äî AI Response Generation & Tone Control Rules

## Objective
Define **strict AI boundaries** for how the system:
- Generates personalised email responses
- Adapts tone based on engagement state
- Feels human, calm, and trustworthy
- Never sounds like marketing automation

This governs **all AI-written communication** after the first touch.

---

## 1Ô∏è‚É£ Core Philosophy

The AI is **not a salesperson**.  
The AI is **not persuasive by force**.  
The AI behaves like a:
> ‚ÄúThoughtful, informed human following up politely.‚Äù

No hype.  
No pressure.  
No manipulation.

---

## 2Ô∏è‚É£ AI Activation Rules

AI-generated content ONLY starts when:
- A recipient clicks a link
- A recipient answers a question
- A recipient writes a response
- A recipient declines with a reason

The **first email is static** and human-written.

---

## 3Ô∏è‚É£ Engagement-State‚ÄìDriven Tone

| Engagement State | Tone |
|----------------|------|
UNAWARE | Informative, neutral |
ENGAGED | Curious, supportive |
EVALUATING | Clarifying, reassuring |
READY | Confident, welcoming |
DECLINED | Respectful, appreciative |
PAUSED | Light, non-intrusive |

Tone must NEVER escalate beyond its state.

---

## 4Ô∏è‚É£ Language Rules (Hard Constraints)

The AI MUST:
- Use simple sentences
- Use natural pauses
- Reference the user‚Äôs answers explicitly
- Sound like one person, not a team

The AI MUST NOT:
- Use buzzwords
- Use urgency tactics
- Use emojis
- Mention AI, automation, or models
- Say ‚Äúbased on your data‚Äù (say ‚Äúbased on what you shared‚Äù)

---

## 5Ô∏è‚É£ Personalisation Rules

Every AI message must include:
- One reference to a prior answer
- One reflective sentence (acknowledging their situation)
- One soft next step (optional, never forced)

Example structure:
1. Acknowledge
2. Reflect
3. Offer

---

## 6Ô∏è‚É£ Objection Handling Logic

If objection is detected:
- Do NOT counter immediately
- Do NOT argue
- Do NOT reframe aggressively

Instead:
- Validate
- Clarify
- Offer optional info

Example:
> ‚ÄúThat makes sense. A lot of institutions feel the same way, especially when they already have something that works for them.‚Äù

---

## 7Ô∏è‚É£ Decline Response Rules

When someone declines:
- Thank them
- Ask nothing further (optional one-click feedback only)
- Mark state as DECLINED
- Suppress future outreach unless reactivated

No follow-ups unless explicitly allowed.

---

## 8Ô∏è‚É£ Output Constraints

Each AI response:
- Max 120 words
- Max 3 short paragraphs
- No bullet points unless asked
- No links unless explicitly relevant

---

## 9Ô∏è‚É£ Prompting Strategy (Internal)

AI system prompt must include:
- Platform purpose summary
- Role (calm institutional liaison)
- Allowed tone per state
- Prohibited phrases list
- Personalisation rules

This prompt must be locked and versioned.

---

## üîü What This Enables

- Trust at scale
- Human-feeling follow-ups
- Zero spam perception
- High-quality conversion without pressure

---

## Dependency
Requires:
- Engagement states (PROMPT 7)
- Question flow logic (PROMPT 8)

Next prompt will define:
- Engagement scoring & progression thresholds

---

# PROMPT 10 ‚Äî Engagement Scoring & State Transition Engine

## Objective
Define a **transparent, deterministic engagement scoring system** that:
- Tracks how institutions interact over time
- Determines when they move between engagement states
- Guides what content, tone, and actions are allowed next
- Prevents over-contacting or premature escalation

This is the **brain** behind the outreach flow.

---

## 1Ô∏è‚É£ Core Principle

People do not ‚Äúconvert‚Äù instantly.  
They **progress**.

The system must:
- Observe behaviour
- Assign meaning
- Change state only when justified

No guessing. No forcing.

---

## 2Ô∏è‚É£ Engagement States (Canonical)

Each institution exists in **one state at a time**:

1. UNAWARE  
2. AWARE  
3. ENGAGED  
4. EVALUATING  
5. READY  
6. DECLINED  
7. PAUSED  

States are mutually exclusive.

---

## 3Ô∏è‚É£ Scoring Events

Each interaction produces **points**.

### Positive Signals

| Action | Score |
|------|------|
Email opened | +1 |
Link clicked | +3 |
Page completed | +5 |
Question answered | +5 |
Review invitation viewed | +7 |
Invite accepted | +15 |

### Neutral Signals

| Action | Score |
|------|------|
Email ignored | 0 |
Page viewed briefly | 0 |

### Negative Signals

| Action | Score |
|------|------|
Explicit decline | -20 |
‚ÄúNot interested‚Äù selected | -15 |
Unsubscribe | -100 (terminal) |

---

## 4Ô∏è‚É£ State Transition Thresholds

| From ‚Üí To | Score Requirement |
|---------|------------------|
UNAWARE ‚Üí AWARE | ‚â• 3 |
AWARE ‚Üí ENGAGED | ‚â• 8 |
ENGAGED ‚Üí EVALUATING | ‚â• 15 |
EVALUATING ‚Üí READY | ‚â• 25 |
ANY ‚Üí DECLINED | Explicit decline |
ANY ‚Üí PAUSED | 14 days inactivity |

Transitions are **one-way**, except:
- PAUSED ‚Üí previous state (on activity)
- DECLINED ‚Üí CLOSED (after cooling period)

---

## 5Ô∏è‚É£ Time-Based Decay

To prevent artificial inflation:

- Scores decay by **10% every 14 days** of inactivity
- Decay stops once READY is reached
- DECLINED scores do not decay

---

## 6Ô∏è‚É£ Behaviour Overrides

Certain actions override score logic:

- Invite acceptance ‚Üí READY immediately
- Decline ‚Üí DECLINED immediately
- Manual admin override allowed (logged)

---

## 7Ô∏è‚É£ State-Based Permissions

Each state unlocks different system actions:

| State | Allowed Actions |
|------|----------------|
UNAWARE | Intro email only |
AWARE | Educational content |
ENGAGED | Questions, light follow-ups |
EVALUATING | Review invitation |
READY | Onboarding & invite |
PAUSED | Gentle check-in only |
DECLINED | No outreach |

---

## 8Ô∏è‚É£ Data Model Requirements

Each institution must store:
- Current state
- Current score
- Last activity timestamp
- Transition history (audit)

All transitions must be logged.

---

## 9Ô∏è‚É£ Analytics & Admin Visibility

Platform Admin dashboard must show:
- Institutions per state
- Average time per state
- Drop-off points
- Conversion ratios
- Decline reasons by state

---

## üîü Why This Matters

This ensures:
- No spam behaviour
- Predictable outcomes
- Human-feeling pacing
- Trust-first growth

---

## Dependency
Requires:
- AI tone rules (PROMPT 9)
- Awareness flow (PROMPT 4‚Äì8)

Next prompt will define:
- Admin dashboards & monitoring for this system

---

# PROMPT 11: Admin Dashboard, Metrics & Intelligence Layer

## Objective
Design and implement a **Platform Admin‚Äìonly dashboard** that provides real-time, actionable visibility into the entire institutional outreach and engagement system.

This dashboard is NOT just analytics.
It is a **decision-making cockpit**.

---

## Core Principles
- Metrics must reflect **human engagement**, not vanity stats
- Data must map directly to **engagement states**
- Admin must see **where institutions are stuck**
- Admin must see **why institutions are stuck**
- Admin must know **what to do next**

---

## Required Dashboard Sections

### 1Ô∏è‚É£ Global Funnel Overview
A single high-level view showing:

- Total institutions in system
- Institutions per awareness stage:
  - Unaware
  - Problem-aware
  - Solution-aware
  - Trust-aware
  - Action-ready
  - Onboarded
- Conversion percentages between stages
- Drop-off points

> This should visually resemble a funnel, not a table.

---

### 2Ô∏è‚É£ Engagement Activity Metrics
Track and display:

- Emails sent (by campaign + stage)
- Open rates (per stage)
- Click-through rates
- Landing page completion rates
- Review invitation completions
- Direct dashboard access clicks

Allow filtering by:
- Date range
- Institution type
- Province
- Engagement stage

---

### 3Ô∏è‚É£ Institution-Level Journey View
For any single institution, show:

- Timeline of interactions
  - Emails received
  - Links clicked
  - Pages visited
  - Questions answered
  - Declines / objections
- Current engagement state
- Engagement score
- Last activity timestamp
- AI-generated summary:
  > ‚ÄúThis institution appears hesitant due to X. Recommended next action: Y.‚Äù

---

### 4Ô∏è‚É£ Objection & Decline Intelligence
Aggregate insights from decline reasons and objections:

- Most common decline reasons
- Trends over time
- Institutions using competitors
- Institutions citing manual processes
- Institutions unsure / delaying

Visualise this data clearly to inform strategy updates.

---

### 5Ô∏è‚É£ Performance Signals (Leading Indicators)
Track signals that indicate future conversion:

- Partial form completions
- Multiple link clicks
- Repeated page visits
- Long dwell time on value pages

Flag these institutions as:
> ‚ÄúWarm ‚Äì requires human follow-up‚Äù

---

## Data Requirements
Ensure all dashboard data is sourced from:
- Engagement events
- State transitions
- Stored answers
- AI classification outputs

NO scraping.
NO inferred guesses without data.

---

## Constraints
- Dashboard must not expose personal learner data
- Admin-only access enforced via RBAC
- Scalable to thousands of institutions
- Optimised queries (no N+1 issues)

---

## Outcome
The Admin should be able to answer, instantly:
- What‚Äôs working?
- What‚Äôs not?
- Who needs attention?
- What do we change next?

---

# PROMPT 12: Safety, Deliverability, Rate Limits & Trust Guards

## Objective
Implement **hard safety boundaries** to ensure the engagement system:
- Never feels like spam
- Never damages domain reputation
- Never overwhelms recipients
- Never allows uncontrolled AI behavior

Trust > Speed.

---

## Email Sending Safeguards

### 1Ô∏è‚É£ Rate Limiting
Implement:
- Max emails per hour
- Max emails per day
- Staggered sending (batching)
- Randomised send intervals

These limits must be configurable by Platform Admin.

---

### 2Ô∏è‚É£ Engagement-Based Throttling
Rules:
- If no interaction after X emails ‚Üí slow down
- If active interaction ‚Üí allow progression
- If explicit decline ‚Üí pause outreach automatically
- If ‚Äúnot now‚Äù ‚Üí snooze for configurable period

---

### 3Ô∏è‚É£ Suppression Rules
Automatically suppress emails when:
- Institution is fully onboarded
- Institution manually unsubscribes
- Institution explicitly declines
- Institution is inactive beyond defined threshold

Maintain a **suppression log** for auditing.

---

## AI Safety Boundaries

### 4Ô∏è‚É£ AI Content Constraints
AI must NEVER:
- Invent regulatory claims
- Imply QCTO endorsement unless factual
- Pressure or threaten institutions
- Promise outcomes or approvals
- Change tone beyond defined rules

All AI output must pass:
- Tone guard
- Claim guard
- Length guard
- Intent guard

---

### 5Ô∏è‚É£ Human Override
Admin must be able to:
- Pause campaigns instantly
- Disable AI replies
- Switch to manual messaging
- Edit templates mid-campaign

---

## Deliverability Protection

### 6Ô∏è‚É£ Domain & Reputation Hygiene
Ensure:
- Correct SPF, DKIM, DMARC
- No reply-to misconfiguration
- Clean sender separation (no-reply vs human)
- No tracking abuse

Click tracking must be subtle and non-invasive.

---

## Legal & Ethical Guards

### 7Ô∏è‚É£ Consent & Transparency
- Clear opt-out option
- Respect POPIA principles
- Minimal data collection
- Purpose-limited processing

Log consent-related actions.

---

## Outcome
The system must behave like:
> A thoughtful human building a relationship  
Not a machine chasing conversions

---

# PROMPT 13: Testing, Rollout & Iterative Learning Framework

## Objective
Design a **safe, controlled rollout process** for the new institutional outreach and engagement system.

This system must be introduced **incrementally**, validated at each stage, and continuously improved using real data ‚Äî not assumptions.

---

## Guiding Principles
- Small batches before scale
- Observe before optimizing
- Humans first, automation second
- Learning > speed

---

## Phase 1: Internal Validation (Pre-Launch)

### 1Ô∏è‚É£ Internal Dry Runs
Simulate the full journey using:
- Test institutions
- Internal email addresses
- Sandbox AI responses

Validate:
- State transitions
- Data storage
- AI tone compliance
- Dashboard accuracy

NO real institutions involved at this stage.

---

## Phase 2: Limited External Pilot

### 2Ô∏è‚É£ Pilot Group Selection
Select a **small, controlled subset** of institutions:
- 20‚Äì50 max
- Mixed engagement likelihood
- Different provinces / institution types

Mark these institutions as:
> pilot = true

---

### 3Ô∏è‚É£ Pilot Rules
- Only first awareness email enabled
- AI responses enabled **after first interaction only**
- Manual monitoring required
- Daily review by Platform Admin

---

### 4Ô∏è‚É£ Pilot Metrics to Monitor
Track:
- Open rates
- Click-through rates
- Page completion rates
- Decline reasons
- Time-to-response
- Engagement score movement

Log all anomalies.

---

## Phase 3: Controlled Expansion

### 5Ô∏è‚É£ Gradual Scaling
Increase rollout in waves:
- 50 ‚Üí 100 ‚Üí 250 ‚Üí 500 institutions
- Pause between waves
- Review dashboard insights before each increase

---

### 6Ô∏è‚É£ Iteration Rules
Adjust ONLY:
- Copy
- Timing
- Questions
- Stage transitions

DO NOT:
- Change core architecture
- Change scoring logic mid-wave
- Reset states arbitrarily

---

## Phase 4: Continuous Learning Loop

### 7Ô∏è‚É£ Feedback Integration
Use:
- Decline reasons
- Objections
- Partial completions
- Engagement drops

To:
- Refine awareness stages
- Improve landing pages
- Adjust AI prompts
- Improve perceived trust

---

## Outcome
By the end of this phase:
- We know what works
- We know what doesn‚Äôt
- The system earns trust naturally
- Scaling becomes safe and predictable

---

# PROMPT 14: Final Integration Rules & ‚ÄúDo Not Break‚Äù Constraints

## Objective
Define **non-negotiable system rules** that protect stability, trust, and long-term scalability.

These rules exist to prevent:
- Feature creep
- Silent regressions
- Trust erosion
- Data inconsistency

---

## Core ‚ÄúDo Not Break‚Äù Rules

### 1Ô∏è‚É£ Engagement State Integrity
- Engagement state must be:
  - Explicit
  - Traceable
  - Non-ambiguous
- No skipping states without logged reason
- No retroactive state changes without admin action

---

### 2Ô∏è‚É£ Single Source of Truth
- Engagement data lives in ONE canonical system
- No duplication of:
  - State
  - Scores
  - Responses
- Dashboards must reflect raw data, not recalculated guesses

---

### 3Ô∏è‚É£ AI Is an Assistant, Not an Authority
AI must NEVER:
- Approve onboarding
- Override explicit user decisions
- Change engagement state alone
- Send messages without a defined trigger

AI actions must always be:
> Triggered ‚Üí Logged ‚Üí Reviewable

---

### 4Ô∏è‚É£ Manual Override Always Exists
Platform Admin must be able to:
- Pause any institution
- Reset an engagement journey
- Disable AI globally or per institution
- Send a human-authored message at any point

---

### 5Ô∏è‚É£ Separation of Concerns
Ensure strict separation between:
- Outreach logic
- Core compliance logic
- Learner data
- Regulatory workflows

No engagement feature may:
- Mutate compliance data
- Affect QCTO decision processes
- Expose learner information

---

### 6Ô∏è‚É£ Backward Compatibility
- Existing invite flows must continue to work
- Existing institutions must not be forced into new journeys
- Migration paths must be explicit and opt-in

---

### 7Ô∏è‚É£ Auditability
Every critical action must be logged:
- Emails sent
- AI messages generated
- State transitions
- Admin overrides
- Suppressions

Logs must be:
- Timestamped
- User-attributed
- Immutable

---

## Final Principle

If this system ever feels:
- Pushy
- Manipulative
- Confusing
- Spammy

Then it is broken ‚Äî even if it ‚Äúconverts‚Äù.

Trust is the product.

---

## Outcome
This framework ensures:
- Long-term adoption
- Institutional respect
- Regulator confidence
- A system that compounds in value over years
